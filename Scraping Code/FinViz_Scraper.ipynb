{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinViz Scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LD0A4LOXmPGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceda7b9e-6c6d-4a5e-e28e-40cb30191601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a ticker: tsla\n",
            "Getting data for tsla...\n",
            "\n",
            "Fundamental Ratios: \n",
            "                 Values\n",
            "Attributes             \n",
            "Index           S&P 500\n",
            "Market Cap     1062.63B\n",
            "Income            3.47B\n",
            "Sales            46.85B\n",
            "Book/sh           27.11\n",
            "...                 ...\n",
            "ATR               65.67\n",
            "Volatility  7.51% 5.58%\n",
            "Prev Close      1026.96\n",
            "Price           1058.12\n",
            "Change            3.03%\n",
            "\n",
            "[72 rows x 1 columns]\n",
            "\n",
            "Recent News: \n",
            "                              News Headline              Article Link\n",
            "Date                                                                 \n",
            "Jan-10-22 10:47PM  Dow Jones Futures Ris...  https://www.investors...\n",
            "08:04PM            Tesla Is Miles Ahead ...  https://www.barrons.c...\n",
            "05:37PM            Tesla Strikes Battery...  https://finance.yahoo...\n",
            "05:15PM            Is Rivian Stock A Buy...  https://www.investors...\n",
            "05:04PM            Apple is still bigger...  https://finance.yahoo...\n",
            "...                                     ...                       ...\n",
            "08:16AM            Dow Jones Futures: Ha...  https://www.investors...\n",
            "08:00AM            Tesla is 'giving cove...  https://finance.yahoo...\n",
            "07:53AM            Tesla Stock Drops Aga...  https://www.barrons.c...\n",
            "06:52AM            These Are The 5 Best ...  https://www.investors...\n",
            "06:40AM            What Tesla's Record P...  https://www.fool.com/...\n",
            "\n",
            "[100 rows x 2 columns]\n",
            "\n",
            "Recent Insider Trades: \n",
            "                  Trader  ...       SEC Form 4\n",
            "Date                      ...                 \n",
            "Jan 05    Taneja Vaibhav  ...  Jan 07 06:36 PM\n",
            "Jan 05    Taneja Vaibhav  ...  Jan 07 06:36 PM\n",
            "Jan 05    Taneja Vaibhav  ...  Jan 07 06:37 PM\n",
            "Dec 31  Kirkhorn Zachary  ...  Jan 04 09:50 PM\n",
            "Dec 28         Musk Elon  ...  Dec 28 08:47 PM\n",
            "...                  ...  ...              ...\n",
            "Jun 28  Baglino Andrew D  ...  Jun 30 07:26 PM\n",
            "Jun 28  Baglino Andrew D  ...  Jun 30 07:26 PM\n",
            "Jun 17  Kirkhorn Zachary  ...  Jun 21 07:20 PM\n",
            "Jun 07    Taneja Vaibhav  ...  Jun 08 08:26 PM\n",
            "Jun 07  Baglino Andrew D  ...  Jun 08 08:13 PM\n",
            "\n",
            "[100 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup as soup\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "pd.set_option('display.max_colwidth', 25)\n",
        "\n",
        "# Input\n",
        "symbol = input('Enter a ticker: ')\n",
        "print ('Getting data for ' + symbol + '...\\n')\n",
        "\n",
        "# Set up scraper\n",
        "url = (\"http://finviz.com/quote.ashx?t=\" + symbol.lower())\n",
        "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "webpage = urlopen(req).read()\n",
        "html = soup(webpage, \"html.parser\")\n",
        "\n",
        "def get_fundamentals():\n",
        "    try:\n",
        "        # Find fundamentals table\n",
        "        fundamentals = pd.read_html(str(html), attrs = {'class': 'snapshot-table2'})[0]\n",
        "        \n",
        "        # Clean up fundamentals dataframe\n",
        "        fundamentals.columns = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n",
        "        colOne = []\n",
        "        colLength = len(fundamentals)\n",
        "        for k in np.arange(0, colLength, 2):\n",
        "            colOne.append(fundamentals[f'{k}'])\n",
        "        attrs = pd.concat(colOne, ignore_index=True)\n",
        "    \n",
        "        colTwo = []\n",
        "        colLength = len(fundamentals)\n",
        "        for k in np.arange(1, colLength, 2):\n",
        "            colTwo.append(fundamentals[f'{k}'])\n",
        "        vals = pd.concat(colTwo, ignore_index=True)\n",
        "        \n",
        "        fundamentals = pd.DataFrame()\n",
        "        fundamentals['Attributes'] = attrs\n",
        "        fundamentals['Values'] = vals\n",
        "        fundamentals = fundamentals.set_index('Attributes')\n",
        "        return fundamentals\n",
        "\n",
        "    except Exception as e:\n",
        "        return e\n",
        "    \n",
        "def get_news():\n",
        "    try:\n",
        "        # Find news table\n",
        "        news = pd.read_html(str(html), attrs = {'class': 'fullview-news-outer'})[0]\n",
        "        links = []\n",
        "        for a in html.find_all('a', class_=\"tab-link-news\"):\n",
        "            links.append(a['href'])\n",
        "        \n",
        "        # Clean up news dataframe\n",
        "        news.columns = ['Date', 'News Headline']\n",
        "        news['Article Link'] = links\n",
        "        news = news.set_index('Date')\n",
        "        return news\n",
        "\n",
        "    except Exception as e:\n",
        "        return e\n",
        "\n",
        "def get_insider():\n",
        "    try:\n",
        "        # Find insider table\n",
        "        insider = pd.read_html(str(html), attrs = {'class': 'body-table'})[0]\n",
        "        \n",
        "        # Clean up insider dataframe\n",
        "        insider = insider.iloc[1:]\n",
        "        insider.columns = ['Trader', 'Relationship', 'Date', 'Transaction', 'Cost', '# Shares', 'Value ($)', '# Shares Total', 'SEC Form 4']\n",
        "        insider = insider[['Date', 'Trader', 'Relationship', 'Transaction', 'Cost', '# Shares', 'Value ($)', '# Shares Total', 'SEC Form 4']]\n",
        "        insider = insider.set_index('Date')\n",
        "        return insider\n",
        "\n",
        "    except Exception as e:\n",
        "        return e\n",
        "\n",
        "print ('Fundamental Ratios: ')\n",
        "print(get_fundamentals())\n",
        "\n",
        "print ('\\nRecent News: ')\n",
        "print(get_news())\n",
        "\n",
        "print ('\\nRecent Insider Trades: ')\n",
        "print(get_insider())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d027gsFrYX1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}